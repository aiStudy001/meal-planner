# ============================================
# AI Meal Planner - Environment Variables
# ============================================

# CRITICAL: Real API keys required (MOCK_MODE=false)
# Get your keys from:
# - Anthropic: https://console.anthropic.com/settings/keys
# - Tavily: https://app.tavily.com/home

# ============================================
# API Keys (REQUIRED)
# ============================================

# Anthropic Claude API Key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Tavily Search API Key (for recipe search and price lookup)
TAVILY_API_KEY=tvly-your-tavily-api-key-here

# ============================================
# LLM Configuration
# ============================================

# Model name (default: claude-3-5-haiku-latest)
# Options: claude-3-5-haiku-latest, claude-3-5-sonnet-latest
LLM_MODEL=claude-3-5-haiku-latest

# Temperature for LLM responses (0.0 - 1.0, default: 0.7)
LLM_TEMPERATURE=0.7

# Maximum tokens per LLM response (default: 2000)
LLM_MAX_TOKENS=2000

# ============================================
# Application Mode
# ============================================

# Mock Mode (MUST be false for production with real API keys)
# Set to true only for testing without API calls
MOCK_MODE=false

# Debug mode (enables detailed logging)
DEBUG=false

# Logging level (INFO, DEBUG, WARNING, ERROR)
LOG_LEVEL=INFO

# ============================================
# Instructions
# ============================================

# 1. Copy this file to .env in the project root:
#    cp .env.example .env
#
# 2. Fill in your API keys above
#
# 3. Start with Docker:
#    docker-compose up -d
#
# 4. Access the application:
#    http://localhost:80
#
# 5. Backend API health check:
#    http://localhost:8000/api/health

# ============================================
# Security Notes
# ============================================

# - NEVER commit .env file to git (it's in .gitignore)
# - Keep API keys secret
# - Rotate keys regularly
# - Use environment-specific .env files for different deployments
